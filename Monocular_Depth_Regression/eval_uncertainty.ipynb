{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses a model trained on KITTI to evaluate uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from utils.evaluation_utils import load_gt_disp_kitti,convert_disps_to_depths_kitti,compute_errors,pred_depth_derivative\n",
    "from uncertainty import monodepth_uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the images test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monodepth_root = ''\n",
    "kitti_root = '/your/kitti_raw/path/'\n",
    "\n",
    "files = monodepth_root + 'utils/filenames/kitti_stereo_2015_test_files_png.txt'\n",
    "files_list = []\n",
    "with open(files, 'r') as f:\n",
    "    for l in f.readlines():\n",
    "        files_list.append(l.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "class params_cl():\n",
    "    \n",
    "    mc_samples = 100\n",
    "    batch_size = 1\n",
    "    do_stereo = False\n",
    "    mode = 'test'\n",
    "    use_deconv = False\n",
    "    encoder = 'vgg'\n",
    "    use_dropout = True\n",
    "    disp_gradient_loss_weight = 0.1\n",
    "    lr_loss_weight = 1.0\n",
    "    width = 512\n",
    "    height = 256\n",
    "    drop_rate = 0.5\n",
    "    \n",
    "    # trained model\n",
    "    checkpoint_path = monodepth_root + 'runs/monodepth_dropout_onedrop15520745/monodepth_dropout_onedrop/model-181250'\n",
    "    \n",
    "params = params_cl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image idx\n",
    "idx = 3\n",
    "\n",
    "# get graph\n",
    "uncertainty_graph = monodepth_uncertainty(params)\n",
    "\n",
    "### Forward Prop MC\n",
    "print('Prop MC forward...')\n",
    "res_mean_mc, res_var_mc, rt_mc = uncertainty_graph.forward_mc(kitti_root + files_list[idx][0])\n",
    "\n",
    "### Forward Prop OUR APPROXIMATION\n",
    "print('Prop OUR forward...')\n",
    "res_mean_our, res_var_our, rt_our = uncertainty_graph.forward_our(kitti_root + files_list[idx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# runtime comparison\n",
    "rt_mc, rt_our"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize qualitative result\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15,10))\n",
    "\n",
    "# mc results\n",
    "fig.colorbar(ax[0,0].imshow(res_mean_mc, cmap='hot', interpolation='nearest'), ax=ax[0,0])\n",
    "fig.colorbar(ax[0,1].imshow(np.log(res_var_mc), cmap='binary', interpolation='nearest'), ax=ax[0,1])\n",
    "\n",
    "# our results\n",
    "fig.colorbar(ax[1,0].imshow(res_mean_our, cmap='hot', interpolation='nearest'), ax=ax[1,0])\n",
    "fig.colorbar(ax[1,1].imshow(np.log(res_var_our), cmap='binary', interpolation='nearest'), ax=ax[1,1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### rmse correlation with uncertainty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predicted disparities and variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test predictions already exist, load them\n",
    "if os.path.isfile('test_preds.p'):\n",
    "    pred_disps, vars_mc, vars_our, rts_mc, rts_our = pickle.load(open('test_preds.p', 'rb'))\n",
    "else:\n",
    "    # get graph\n",
    "    uncertainty_graph = monodepth_uncertainty(params)\n",
    "\n",
    "    # gt_depths, pred_depths, pred_disparities_resized = convert_disps_to_depths_kitti(gt_disparities, pred_disparities)\n",
    "\n",
    "    rts_mc, rts_our = [], []\n",
    "    pred_disps = []\n",
    "    vars_mc, vars_our = [], []\n",
    "    for i in tqdm(range(len(files_list))):\n",
    "        ##########################\n",
    "        ### Forward Prop MC\n",
    "        mean_mc, var_mc, rt_mc = uncertainty_graph.forward_mc(kitti_root + files_list[i][0], pp=False)\n",
    "\n",
    "        rts_mc.append(rt_mc)\n",
    "        pred_disps.append(mean_mc)\n",
    "        vars_mc.append(var_mc)\n",
    "        ##########################\n",
    "\n",
    "        ##########################\n",
    "        ### Forward Prop OUR APPROXIMATION\n",
    "        mean_our, var_our, rt_our = uncertainty_graph.forward_our(kitti_root + files_list[i][0], pp=False)\n",
    "\n",
    "        rts_our.append(rt_our)\n",
    "        vars_our.append(var_our)\n",
    "        ##########################\n",
    "\n",
    "    pred_disps = np.array(pred_disps)  \n",
    "    \n",
    "    pickle.dump([pred_disps, vars_mc, vars_our, rts_mc, rts_our], open('test_preds.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute error-variance pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as in original work\n",
    "min_depth = 1e-3\n",
    "max_depth = 80\n",
    "\n",
    "# load gt and convert disps to depths\n",
    "gt_disps = load_gt_disp_kitti('/media/sdb/kitti_raw')\n",
    "gt_depths, pred_depths, pred_disparities_resized = convert_disps_to_depths_kitti(gt_disps, pred_disps)\n",
    "\n",
    "abs_diff_var = []\n",
    "for i in tqdm(range(len(gt_depths))):\n",
    "    \n",
    "    # get depths & vars\n",
    "    gt_depth = gt_depths[i]\n",
    "    pred_depth = pred_depths[i]\n",
    "    v_our = vars_our[i]\n",
    "    v_mc = vars_mc[i]\n",
    "    \n",
    "    # get pred disps and derivatives of depth wrt disps\n",
    "    pred_disp = pred_disparities_resized[i]\n",
    "    dDepth = pred_depth_derivative(pred_disp)\n",
    "    \n",
    "    h, w = gt_depth.shape\n",
    "    v_our = cv2.resize(v_our[0], (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    v_mc = cv2.resize(v_mc[0], (w, h), interpolation=cv2.INTER_LINEAR)\n",
    "    \n",
    "    # enforce thresholds\n",
    "    pred_depth[pred_depth < min_depth] = min_depth\n",
    "    pred_depth[pred_depth > max_depth] = max_depth\n",
    "\n",
    "    # get gt disps and mask legit disps\n",
    "    gt_disp = gt_disps[i]\n",
    "    mask = gt_disp > 0\n",
    "    \n",
    "    # propagate variance through depth computation\n",
    "    v_our = v_our[mask] * dDepth[mask]**2\n",
    "    v_mc = v_mc[mask] * dDepth[mask]**2\n",
    "\n",
    "    # compute absolute disparity difference\n",
    "    disp_diff = np.abs(gt_disp[mask] - pred_disp[mask])\n",
    "#     bad_pixels = np.logical_and(disp_diff >= 3, (disp_diff / gt_disp[mask]) >= 0.05)\n",
    "\n",
    "    # compute absule depth error\n",
    "    abs_diff = np.abs(gt_depth[mask] - pred_depth[mask])\n",
    "\n",
    "    # store all absolute error-variances-pairs\n",
    "    for i in range(len(abs_diff)):\n",
    "        abs_diff_var.append([abs_diff[i], v_mc[i], v_our[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error values\n",
    "errs = np.array([d[0] for d in abs_diff_var])\n",
    "# convert to np arrays\n",
    "abs_diff_var = np.array([np.array(d) for d in abs_diff_var])\n",
    "# percentiles\n",
    "intervals = np.percentile(errs, np.arange(1, 101, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum variances in error intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros(len(intervals))\n",
    "sums_our = np.zeros(len(intervals))\n",
    "sums_mc = np.zeros(len(intervals))\n",
    "for i in tqdm(range(len(intervals))):\n",
    "    if i == 0:\n",
    "        mask = np.logical_and(abs_diff_var[:, 0] > 0, abs_diff_var[:, 0] <= intervals[i])\n",
    "    else:\n",
    "        mask = np.logical_and(abs_diff_var[:, 0] > intervals[i-1], abs_diff_var[:, 0] <= intervals[i])\n",
    "    counts[i] = mask.sum()\n",
    "    sums_our[i] = np.sqrt(abs_diff_var[mask, 2]).sum()\n",
    "    sums_mc[i] = np.sqrt(abs_diff_var[mask, 1]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dump results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump({\n",
    "    'intervals': intervals[:-1], \n",
    "    'mean_unc_mc': (sums_mc/counts)[:-1],\n",
    "    'mean_unc_our': (sums_our/counts)[:-1],\n",
    "}, open('results/quantitative/unc_error_corr.p', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### variance differences and runtime comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_disps = load_gt_disp_kitti('/media/sdb/kitti_raw')\n",
    "\n",
    "# iterate over different number of mc samples\n",
    "mean_mc_rts, mean_our_rts = [], []\n",
    "var_diffs_all = []\n",
    "for i in np.arange(2, 102, 10):\n",
    "\n",
    "    print(str(i) + ' samples...')\n",
    "    params.mc_samples = i\n",
    "    uncertainty_graph = monodepth_uncertainty(params)\n",
    "\n",
    "    rts_mc, rts_our = [], []\n",
    "    var_diffs = []\n",
    "    for i in tqdm(range(len(files_list))):\n",
    "        ##########################\n",
    "        ### Forward Prop MC\n",
    "        mean_mc, var_mc, rt_mc = uncertainty_graph.forward_mc(kitti_root + files_list[i][0], pp=False)\n",
    "        rts_mc.append(rt_mc)\n",
    "        ##########################\n",
    "\n",
    "\n",
    "        ##########################\n",
    "        ### Forward Prop OUR APPROXIMATION\n",
    "        mean_our, var_our, rt_our = uncertainty_graph.forward_our(kitti_root + files_list[i][0], pp=False)\n",
    "\n",
    "        rts_our.append(rt_our)\n",
    "        ##########################\n",
    "        \n",
    "        var_diffs.append(np.abs(var_our - var_mc).mean())\n",
    "        \n",
    "    mean_mc_rts.append(np.mean(rts_mc))\n",
    "    mean_our_rts.append(np.mean(rts_our))\n",
    "    var_diffs_all.append(np.mean(var_diffs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('results/quantitative/rts&abs_diffs.p'):\n",
    "    pickle.dump({\n",
    "        'samples': np.arange(2, 102, 10),\n",
    "        'mean_rt_mc': mean_mc_rts,\n",
    "        'mean_rt_our': mean_our_rts,\n",
    "        'mean_abs_diff_vars': var_diffs_all\n",
    "    }, open('results/quantitative/rts&abs_diffs.p', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
